{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMC0C9vlHK4X"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[1]:\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# # parameters\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "path = 'Train'\n",
        "labelsfile = 'labels.csv'\n",
        "batch_size_val = 50\n",
        "per_epoch_steps = 502\n",
        "epochs_val =10\n",
        "image_dim = (32,32,3)\n",
        "test_ratio = 0.2\n",
        "val_ratio = 0.2\n",
        "\n",
        "\n",
        "# # importing all the images\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "\n",
        "count = 0\n",
        "images= []\n",
        "classNo = []\n",
        "mylist = os.listdir(path)\n",
        "print('TOTAL CLASS DETECTED :',len(mylist))\n",
        "total_classes = len(mylist)\n",
        "print('IMPORTING CLASSES..............................')\n",
        "for i in range(0 , len(mylist)):\n",
        "    mypiclist = os.listdir(path+'/'+str(count))\n",
        "    for j in mypiclist:\n",
        "        img = Image.open(path+'/'+str(count)+'/'+str(j))\n",
        "        img = img.resize((32,32))\n",
        "        currImg = np.array(img)\n",
        "        images.append(currImg)\n",
        "        classNo.append(count)\n",
        "    print(count,end = ' ')\n",
        "    count += 1\n",
        "\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "\n",
        "print(' ')\n",
        "images = np.array(images)\n",
        "classNo = np.array(classNo)\n",
        "print(images.shape)\n",
        "print(classNo.shape)\n",
        "\n",
        "\n",
        "# # split data\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "x_train , x_test , y_train , y_test = train_test_split(images, classNo , test_size = test_ratio)\n",
        "x_train , x_val , y_train , y_val = train_test_split(x_train , y_train , test_size = val_ratio)\n",
        "#x_train = array of images to train\n",
        "#y_train = corresponding class ID\n",
        "\n",
        "\n",
        "# # to check that no. of images matches the labels for each data set\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "\n",
        "print('DATA SHAPE')\n",
        "print('TRAIN:',end= ' ');print(x_train.shape,y_train.shape)\n",
        "print('VALIDATION:',end= ' ');print(x_val.shape,y_val.shape)\n",
        "print('TEST:',end= ' ');print(x_test.shape,y_test.shape)\n",
        "\n",
        "\n",
        "# # reading the labels\n",
        "\n",
        "# In[7]:\n",
        "\n",
        "\n",
        "data = pd.read_csv(labelsfile)\n",
        "print(data.shape)\n",
        "\n",
        "\n",
        "# # displaying some sample images from the data\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "\n",
        "samples_no = []\n",
        "cols =5\n",
        "num_classes = total_classes\n",
        "fig , axis = plt.subplots(nrows=num_classes , ncols=cols , figsize = (5,300))\n",
        "fig.tight_layout()\n",
        "for i in range(cols):\n",
        "    for index ,rows in data.iterrows():\n",
        "        x_selected = x_train[y_train==index]\n",
        "        axis[index][i].imshow(x_selected[random.randint(0,len(x_selected)-1),:,:] , cmap = plt.get_cmap('gray'))\n",
        "        axis[index][i].axis('off')\n",
        "        if i == 2:\n",
        "            axis[index][i].set_title(str(index)+'-'+rows['names'])\n",
        "            samples_no.append(len(x_selected))\n",
        "\n",
        "\n",
        "# # displaying a bar chart\n",
        "# \n",
        "\n",
        "# In[9]:\n",
        "\n",
        "\n",
        "print(samples_no)\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.bar(range(0 , num_classes) ,samples_no)\n",
        "plt.title('DISTRIBUTION OF TRAINING DATASET')\n",
        "plt.xlabel('CLASS NUMBER')\n",
        "plt.ylabel('NUMBER OF IMAGES')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# # Preprocessing the images\n",
        "\n",
        "# In[10]:\n",
        "\n",
        "\n",
        "def grayscale(img):\n",
        "    img = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
        "    return img\n",
        "\n",
        "def equalize(img):\n",
        "    img = cv2.equalizeHist(img)\n",
        "    return img\n",
        "\n",
        "def preprocessing(img):\n",
        "    img = grayscale(img)  #converts the image into gray\n",
        "    img = equalize(img)   #standardize the lighting of the image\n",
        "    img = img/255         #to normalize values between 0 and 1 instead of 0 to 255\n",
        "    return img\n",
        "    \n",
        "x_train = np.array(list(map(preprocessing ,x_train))) #to iterate through all images and preprocess the images\n",
        "x_val = np.array(list(map(preprocessing ,x_val)))\n",
        "x_test = np.array(list(map(preprocessing ,x_test)))\n",
        "\n",
        "cv2.imshow('Gray Scale images', x_train[random.randint(0,len(x_train)-1)]) #to check if the training is done properly\n",
        "cv2.waitKey(0)\n",
        "\n",
        "\n",
        "# # Add a depth of 1\n",
        "\n",
        "# In[11]:\n",
        "\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
        "x_val = x_val.reshape(x_val.shape[0],x_val.shape[1],x_val.shape[2],1)\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)\n",
        "\n",
        "\n",
        "# # Augmentation of images : to make them more generic\n",
        "\n",
        "# In[12]:\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(width_shift_range=0.1,  #0.1 = 10% horizontal shift\n",
        "                             height_shift_range=0.1,  #vertical shift\n",
        "                             zoom_range=0.2,  #0.2 means zoom range is 1 +- 0.2\n",
        "                             shear_range=0.1,  #magnitude of shear angle\n",
        "                             rotation_range=10 #degrees\n",
        "                            )\n",
        "\n",
        "datagen.fit(x_train)\n",
        "batches = datagen.flow(x_train ,y_train , batch_size=20)  #requests datagen togenerates the images #batch size = no. of images generated each time its called\n",
        "x_batch , y_batch = next(batches)\n",
        "\n",
        "\n",
        "# # to show augmented image samples\n",
        "\n",
        "# In[13]:\n",
        "\n",
        "\n",
        "fig , axs = plt.subplots(1,15,figsize=(20,5))\n",
        "fig.tight_layout\n",
        "for i in range(15):\n",
        "    axs[i].imshow(x_batch[i].reshape(image_dim[0] , image_dim[1]))\n",
        "    axs[i].axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# In[14]:\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train,total_classes)\n",
        "y_val = to_categorical(y_val,total_classes)\n",
        "y_test = to_categorical(y_test,total_classes)\n",
        "\n",
        "\n",
        "# # Convolutional neural network model\n",
        "\n",
        "# In[15]:\n",
        "\n",
        "\n",
        "def mymodel():\n",
        "    filter_no = 60\n",
        "    filter1_size = (5,5) #this is the kernel that moves around the image to get the features\n",
        "                        #this will remove 2 piece from the each border when using (32,32) image\n",
        "    filter2_size = (3,3)\n",
        "    poolsize = (2,2)   #scale down all features map generalizing more , reducws overfitting\n",
        "    nodes_count = 500  #total no of nodes in hidden layer\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filter_no,filter1_size , input_shape = (image_dim[0],image_dim[1],1) , activation ='relu')) #adding more convolutional layer to the model\n",
        "    model.add(Conv2D(filter_no ,filter1_size,activation = 'relu'))\n",
        "    model.add(MaxPool2D(pool_size = poolsize)) #does not affect the no of filters\n",
        "    \n",
        "    model.add(Conv2D(filter_no//2,filter2_size,activation='relu'))\n",
        "    model.add(Conv2D(filter_no//2,filter2_size,activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size = poolsize)) \n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(nodes_count,activation='relu'))\n",
        "    model.add(Dropout(0.5))  #input nodes dropped with each update 1 for all and 0 for None\n",
        "    model.add(Dense(total_classes, activation ='softmax'))  #output layer\n",
        "    \n",
        "    #compiling the model\n",
        "    model.compile(Adam(lr =0.001) , loss ='categorical_crossentropy' , metrics =['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# # training the model\n",
        "\n",
        "# In[17]:\n",
        "\n",
        "\n",
        "model =mymodel()\n",
        "print(model.summary())\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size_val), \n",
        "                              steps_per_epoch = per_epoch_steps, \n",
        "                              epochs = epochs_val,\n",
        "                              validation_data=(x_val, y_val),\n",
        "                              shuffle = 1)\n",
        "\n",
        "\n",
        "# # plot\n",
        "\n",
        "# In[20]:\n",
        "\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training' ,'validation'])\n",
        "plt.title('LOSS')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['training' ,'validation'])\n",
        "plt.title('ACCURACY')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "\n",
        "# # storing the object as a joblib object\n",
        "\n",
        "# In[33]:\n",
        "\n",
        "\n",
        "model.save('model_trained.h5')\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7wMDVLS_HX6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1CvvDxAtHYPe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}